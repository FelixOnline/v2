---
title: >
  There’s no need to fear robots
subtitle: >
  Artificial Intelligence won't overtake us
date: "2011-03-10 18:59:11 +0000"

# Attributes from Felix Online V1
id: "1048"
old_path: /science/1048/theres-no-need-to-fear-robots
aliases:
 - /science/1048/theres-no-need-to-fear-robots
imported: true
comments:

# Article Taxonomies
categories:
 - science
tags:
 - imported
 - image
 - multi-author
authors:
 - felix
 - ks607
highlights:

# Homepage control params
headline: true
featured: true
image: "http://felixonline.co.uk/img/upload/201103101852-nm1010-terminat.jpg"
image_caption: ""
---

The Polish restaurant on Exhibition Road, [Ognisko](http://www.ognisko.com/), seems to be out of its time. The décor and atmosphere would seem to suggest that mink-ensconced flappers and mustachioed airmen could come swooping into the dining hall at any moment. It’s in these surroundings that I have the pleasure to sit beside Emeritus Professor Igor Alexander, who has just spent the previous hour or so talking about how the interconnectedness of neural networks in the brain could be the cause of consciousness itself. I ask him if his understanding of the brain has altered his experience of the world and his awareness of his own consciousness. He gives a short sincere laugh and replies that it’s made him feel much more comfortable about the whole thing.

During his lecture, entitled: “Can mankind survive in the age of information?” and hosted by [Friends of Imperial](http://www.friendsofimperial.org.uk/), he displayed a similar air of ease and confidence. He readily admits at the beginning that the title is a tad misleading. It’s too easy a question, he suggests, and it can be answered “in three seconds flat.” The answer is obviously Yes, he says. Sitting at the front of the lecture theatre, I can almost feel the quizzical looks of the audience behind me demanding: “then what is this lecture about?”

Asking whether mankind can survive in the 21st century, in this age of information, implies that there is something to fear. The point of Professor Alexander’s lecture – starting with knocking down the title at the beginning – is to show that those who gloomily predict the rise of computers (and the fall of mankind that usually accompanies their narrative) or the damaging effect of the Internet on our brains, are misunderstanding something crucial about our brains and consciousness.

As a man who has devoted his entire career to understanding the mind, [Professor Alexander](http://en.wikipedia.org/wiki/Igor_Aleksander) is more than qualified to make such a statement. He is an electrical engineer who designed and built the world’s first neural pattern recognition system and he has published over 200 scientific papers and 12 books about the mind. Why shouldn’t an electrical engineer pioneer research into the brain? is the challenge he raises when he says: “The brain is a physical, chemical and electrical device”, therefore it can be analysed using the tools of physicists, chemists and electrical engineers.

So what did people like Ed Fredkin, who in 1983 suggested on the BBC’s Horizon that within eight years computers would have grown so powerful that they would keep humans as pets, get wrong about consciousness? Professor Alexander first explained what might conjure up consciousness. Neurons behave like the components of a circuit, in that they perform the same sort of logical operations. However, they don’t have the same linear relationship between input and output. They’re looped and networked in such a way that they pass signals between each other and, in his words, “reverberate”. This internal reverberation, which may not result in any output, could be the source of thought. The more interconnected a network, the greater the ability for conscious thought – this is where I began to shudder at the thought of someone reducing the interconnectedness of my neurons and wiping away my consciousness in the process, silly I know.

The crucial point, however, is that this is not enough for consiciousness. These reverberations must have some correlation with the outside world. In short, you must be able to interpret and recognise the world around you. The neurons also form imprints and patterns of reverberations that can be triggered and fired off without external input – this is where memory and our ability to interpret and recognise could reside.

Coming back to robots, to the fear of the rise of the machines, a being’s consciousness is dependent on its needs and its experience of the world. A packaging robot’s consciousness is grounded solely in its experience of being a packaging robot. Similarly its needs are simple; if it’s constantly plugged in, why would it revolt against mankind?

The problem with his argument, I guess, is that one can always have nightmares about a specific robot in a highly specific set of circumstances that would crush all of mankind. Professor Alexander obviously doesn’t worry about such things (who seriously does?) but the lecture still left me unsettled. Although he claimed to be more at ease with his consiciousness through understanding where it might arise, I became more worried about the fragility of my identity. Each moment of our existence is unique and definable, he says (well thank goodness!) but as you reduce the interconnectedness of a neural system, your capacity to distinguish between them, and thus your ability to interact with the world diminishes.

Oh dear. I’d better lay off the wine then!

[Friends of Imperial’s next lecture](http://www.friendsofimperial.org.uk/FOIC-Index.php?pg=FullEvent&from=Our-Events&ev=66) will be by [Professor Frank Berkshire](http://www3.imperial.ac.uk/people/f.berkshire) on the 17th of March, in the Sir Alexander Fleming Building from 19:00. It is entitled “Chaotic cards and dynamic dice” and looks at how mathematics can be used for gain in gambling.
